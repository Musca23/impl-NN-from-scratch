The project consists in the implementation of an Artificial Neural Network built from scratch using Python, without using pre-built libraries.
Specifically, the model we used for this project is a simple multilayer perceptron: however, the architecture we implemented is modular so it is possible to add an arbitrary number of layers and units in order to build a more complex network.\\
The overall validation schema consisted in a preliminary screening phase to reduce the hyperparameters search space, followed by a first coarse grid-search and a second but finer one. All the explored models are validated with a 5-fold cross validation. The resulting final model is a 2 hidden layer network with 20 units and ReLU activation for both layers, momentum of 0.6, mini-batch size of 145, an eta value of 0.001, no regularization and no learning rate decay.